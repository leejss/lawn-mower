name: Scheduled Scrape and Upload

on:
  schedule:
    - cron: "0 * * * *"
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

concurrency:
  group: scrape-and-upload
  cancel-in-progress: false

jobs:
  scrape-upload:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2

      - name: Install dependencies
        run: bun install

      - name: Install Playwright browser
        run: bunx playwright install --with-deps chromium

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_GHA_ROLE_ARN }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Scrape mainnews
        env:
          PLAYWRIGHT_HEADLESS: "true"
        run: bun run scrape:mainnews

      - name: Upload raw news to DynamoDB
        env:
          RAW_NEWS_TABLE: ${{ secrets.RAW_NEWS_TABLE }}
        run: bun run pipeline:upload

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: scrape-output-${{ github.run_id }}
          path: out/
